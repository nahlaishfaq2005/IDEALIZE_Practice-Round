{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b014a",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pd.read_csv(\"data/preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dee6cf",
   "metadata": {},
   "source": [
    "##  Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessed_df.drop(columns=[\"RainTomorrow\"])\n",
    "y = preprocessed_df[\"RainTomorrow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RainToday_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33642</th>\n",
       "      <td>-1.266628</td>\n",
       "      <td>1.318400</td>\n",
       "      <td>1.923685</td>\n",
       "      <td>-0.277685</td>\n",
       "      <td>-0.659159</td>\n",
       "      <td>-3.775571e-01</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>-1.371700</td>\n",
       "      <td>0.342057</td>\n",
       "      <td>-0.417345</td>\n",
       "      <td>-0.994959</td>\n",
       "      <td>-1.290426</td>\n",
       "      <td>-2.907191e-01</td>\n",
       "      <td>-0.533415</td>\n",
       "      <td>1.392768</td>\n",
       "      <td>1.938134</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.085800</td>\n",
       "      <td>1.634134</td>\n",
       "      <td>-0.532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63550</th>\n",
       "      <td>1.644151</td>\n",
       "      <td>-0.465103</td>\n",
       "      <td>-0.902549</td>\n",
       "      <td>-0.254160</td>\n",
       "      <td>1.379883</td>\n",
       "      <td>1.604096e+00</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>1.461288</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>-0.417345</td>\n",
       "      <td>-0.994959</td>\n",
       "      <td>0.413574</td>\n",
       "      <td>-6.911065e-01</td>\n",
       "      <td>-1.087384</td>\n",
       "      <td>-0.490470</td>\n",
       "      <td>-0.782056</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.299239</td>\n",
       "      <td>-0.118965</td>\n",
       "      <td>-0.532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106115</th>\n",
       "      <td>0.180396</td>\n",
       "      <td>0.254556</td>\n",
       "      <td>0.475416</td>\n",
       "      <td>-0.160060</td>\n",
       "      <td>0.956596</td>\n",
       "      <td>2.321823e-01</td>\n",
       "      <td>1.761797</td>\n",
       "      <td>1.574738</td>\n",
       "      <td>-0.564621</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>0.695128</td>\n",
       "      <td>-1.144368</td>\n",
       "      <td>-2.233339e+00</td>\n",
       "      <td>-2.180350</td>\n",
       "      <td>0.343095</td>\n",
       "      <td>0.527127</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692519</td>\n",
       "      <td>1.634134</td>\n",
       "      <td>-0.532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76918</th>\n",
       "      <td>0.512371</td>\n",
       "      <td>2.272731</td>\n",
       "      <td>1.473738</td>\n",
       "      <td>-0.277685</td>\n",
       "      <td>1.301793</td>\n",
       "      <td>-7.586442e-01</td>\n",
       "      <td>1.093460</td>\n",
       "      <td>1.390112</td>\n",
       "      <td>-0.111282</td>\n",
       "      <td>0.385847</td>\n",
       "      <td>0.272606</td>\n",
       "      <td>0.608317</td>\n",
       "      <td>-1.121152e+00</td>\n",
       "      <td>-1.252077</td>\n",
       "      <td>2.071969</td>\n",
       "      <td>1.618112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487322</td>\n",
       "      <td>-1.579881</td>\n",
       "      <td>-0.532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>0.282799</td>\n",
       "      <td>-0.777998</td>\n",
       "      <td>-0.424479</td>\n",
       "      <td>-0.277685</td>\n",
       "      <td>0.956596</td>\n",
       "      <td>-5.415574e-16</td>\n",
       "      <td>1.165612</td>\n",
       "      <td>1.574738</td>\n",
       "      <td>-0.904625</td>\n",
       "      <td>1.074297</td>\n",
       "      <td>-0.308361</td>\n",
       "      <td>-0.657511</td>\n",
       "      <td>-1.685880e-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.397851</td>\n",
       "      <td>-0.331115</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.085800</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>-0.532569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Location   MinTemp   MaxTemp  Rainfall  WindGustDir  WindGustSpeed  \\\n",
       "33642  -1.266628  1.318400  1.923685 -0.277685    -0.659159  -3.775571e-01   \n",
       "63550   1.644151 -0.465103 -0.902549 -0.254160     1.379883   1.604096e+00   \n",
       "106115  0.180396  0.254556  0.475416 -0.160060     0.956596   2.321823e-01   \n",
       "76918   0.512371  2.272731  1.473738 -0.277685     1.301793  -7.586442e-01   \n",
       "5727    0.282799 -0.777998 -0.424479 -0.277685     0.956596  -5.415574e-16   \n",
       "\n",
       "        WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
       "33642     0.574642   -1.371700      0.342057     -0.417345    -0.994959   \n",
       "63550     0.574642    1.461288      0.908731     -0.417345    -0.994959   \n",
       "106115    1.761797    1.574738     -0.564621      0.041622     0.695128   \n",
       "76918     1.093460    1.390112     -0.111282      0.385847     0.272606   \n",
       "5727      1.165612    1.574738     -0.904625      1.074297    -0.308361   \n",
       "\n",
       "        Humidity3pm   Pressure9am  Pressure3pm   Temp9am   Temp3pm  \\\n",
       "33642     -1.290426 -2.907191e-01    -0.533415  1.392768  1.938134   \n",
       "63550      0.413574 -6.911065e-01    -1.087384 -0.490470 -0.782056   \n",
       "106115    -1.144368 -2.233339e+00    -2.180350  0.343095  0.527127   \n",
       "76918      0.608317 -1.121152e+00    -1.252077  2.071969  1.618112   \n",
       "5727      -0.657511 -1.685880e-14     0.000000 -0.397851 -0.331115   \n",
       "\n",
       "        RainTomorrow      Year     Month  RainToday_Yes  \n",
       "33642              0 -1.085800  1.634134      -0.532569  \n",
       "63550              1 -0.299239 -0.118965      -0.532569  \n",
       "106115             0 -0.692519  1.634134      -0.532569  \n",
       "76918              0  0.487322 -1.579881      -0.532569  \n",
       "5727               1 -1.085800  0.465401      -0.532569  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0a8a6",
   "metadata": {},
   "source": [
    "## Try ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5265225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn xgboost lightgbm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "# Define models\n",
    "models = {\n",
    "    #\"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    #\"Naive Bayes\": GaussianNB(),\n",
    "    #\"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "#     \"SVM (RBF Kernel)\": SVC(kernel='rbf', probability=True),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "#     \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "#     \"LightGBM\": lgb.LGBMClassifier()\n",
    " }\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(x,y)     \n",
    "    preds = model.predict(x)\n",
    "   \n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model saved to knn_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train KNN model\n",
    "knn_model = AdaBoostClassifier()\n",
    "knn_model.fit(x,y)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib_file = \"knn_model.joblib\"\n",
    "joblib.dump(knn_model, joblib_file)\n",
    "\n",
    "print(f\"KNN model saved to {joblib_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_pickle(\"idealize_1_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8093eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"Data\\processed\\preprocessed_train.csv\")\n",
    "\n",
    "# Save ID column for final output\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# Drop unused columns for prediction\n",
    "X_new = test_df.drop(['id','Day'], axis=1)\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load(\"knn_model.joblib\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'RainTomorrow': predictions\n",
    "})\n",
    "\n",
    "# Save to Excel (or CSV depending on submission format)\n",
    "submission_df.to_csv(\"submission_file.csv\", index=False)\n",
    "\n",
    "print(\"ðŸŽ‰ Submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aad300",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Day\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[233]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLogistic Regression (L2)\u001b[39m\u001b[33m\"\u001b[39m: log_reg_l2,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLogistic Regression (L1)\u001b[39m\u001b[33m\"\u001b[39m: log_reg_l1\n\u001b[32m     13\u001b[39m }.items():\n\u001b[32m     14\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     acc = accuracy_score(y_test, preds)\n\u001b[32m     17\u001b[39m     f1 = f1_score(y_test, preds, average=\u001b[33m'\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MY PROJECTS\\PANDAS_1\\pandalearning\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:374\u001b[39m, in \u001b[36mLinearClassifierMixin.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[33;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[32m    362\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    373\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    376\u001b[39m     indices = xp.astype(scores > \u001b[32m0\u001b[39m, indexing_dtype(xp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MY PROJECTS\\PANDAS_1\\pandalearning\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    348\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    349\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m scores = safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    354\u001b[39m     xp.reshape(scores, (-\u001b[32m1\u001b[39m,))\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (scores.ndim > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[32m    357\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MY PROJECTS\\PANDAS_1\\pandalearning\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MY PROJECTS\\PANDAS_1\\pandalearning\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Day\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# L2 Regularized Logistic Regression (Ridge)\n",
    "log_reg_l2 = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=1000)\n",
    "\n",
    "# L1 Regularized Logistic Regression (Lasso)\n",
    "log_reg_l1 = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Fit and evaluate both\n",
    "for name, model in {\n",
    "    \"Logistic Regression (L2)\": log_reg_l2,\n",
    "    \"Logistic Regression (L1)\": log_reg_l1\n",
    "}.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average='weighted')\n",
    "    print(f\"{name}: Accuracy = {acc:.4f}, F1 Score = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandalearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
