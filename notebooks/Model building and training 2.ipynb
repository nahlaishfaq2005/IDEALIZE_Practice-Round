{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04fa4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b014a",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48aca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pd.read_pickle(\"idealize_1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dee6cf",
   "metadata": {},
   "source": [
    "##  Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5c0e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa1f97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessed_df.drop(columns=[\"RainTomorrow\"])\n",
    "y = preprocessed_df[\"RainTomorrow\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b068bad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113754, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9535f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113754 entries, 0 to 113753\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Location       113754 non-null  float64\n",
      " 1   MinTemp        113754 non-null  float64\n",
      " 2   MaxTemp        113754 non-null  float64\n",
      " 3   Rainfall       113754 non-null  float64\n",
      " 4   WindGustDir    113754 non-null  float64\n",
      " 5   WindGustSpeed  113754 non-null  float64\n",
      " 6   WindDir9am     113754 non-null  float64\n",
      " 7   WindDir3pm     113754 non-null  float64\n",
      " 8   WindSpeed9am   113754 non-null  float64\n",
      " 9   WindSpeed3pm   113754 non-null  float64\n",
      " 10  Humidity9am    113754 non-null  float64\n",
      " 11  Humidity3pm    113754 non-null  float64\n",
      " 12  Pressure9am    113754 non-null  float64\n",
      " 13  Pressure3pm    113754 non-null  float64\n",
      " 14  Temp9am        113754 non-null  float64\n",
      " 15  Temp3pm        113754 non-null  float64\n",
      " 16  RainTomorrow   113754 non-null  int64  \n",
      " 17  Year           113754 non-null  float64\n",
      " 18  Month          113754 non-null  float64\n",
      " 19  RainToday_Yes  113754 non-null  float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 17.4 MB\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f416f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91003, 22751, 91003, 22751)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0a8a6",
   "metadata": {},
   "source": [
    "## Try DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8439c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4238 - val_accuracy: 0.8492 - val_loss: 0.3543\n",
      "Epoch 2/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3685 - val_accuracy: 0.8504 - val_loss: 0.3497\n",
      "Epoch 3/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3683 - val_accuracy: 0.8498 - val_loss: 0.3495\n",
      "Epoch 4/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3660 - val_accuracy: 0.8508 - val_loss: 0.3473\n",
      "Epoch 5/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8453 - loss: 0.3635 - val_accuracy: 0.8523 - val_loss: 0.3457\n",
      "Epoch 6/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3652 - val_accuracy: 0.8522 - val_loss: 0.3450\n",
      "Epoch 7/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.3632 - val_accuracy: 0.8515 - val_loss: 0.3443\n",
      "Epoch 8/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.8463 - loss: 0.3589 - val_accuracy: 0.8523 - val_loss: 0.3464\n",
      "Epoch 9/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8449 - loss: 0.3623 - val_accuracy: 0.8534 - val_loss: 0.3434\n",
      "Epoch 10/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8464 - loss: 0.3584 - val_accuracy: 0.8534 - val_loss: 0.3421\n",
      "Epoch 11/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3604 - val_accuracy: 0.8539 - val_loss: 0.3420\n",
      "Epoch 12/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8487 - loss: 0.3584 - val_accuracy: 0.8522 - val_loss: 0.3428\n",
      "Epoch 13/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.3550 - val_accuracy: 0.8538 - val_loss: 0.3402\n",
      "Epoch 14/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8471 - loss: 0.3566 - val_accuracy: 0.8530 - val_loss: 0.3392\n",
      "Epoch 15/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8474 - loss: 0.3561 - val_accuracy: 0.8551 - val_loss: 0.3403\n",
      "Epoch 16/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 9ms/step - accuracy: 0.8473 - loss: 0.3541 - val_accuracy: 0.8549 - val_loss: 0.3428\n",
      "Epoch 17/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8495 - loss: 0.3528 - val_accuracy: 0.8547 - val_loss: 0.3390\n",
      "Epoch 18/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.8490 - loss: 0.3534 - val_accuracy: 0.8536 - val_loss: 0.3389\n",
      "Epoch 19/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3514 - val_accuracy: 0.8530 - val_loss: 0.3394\n",
      "Epoch 20/20\n",
      "\u001b[1m2844/2844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8481 - loss: 0.3546 - val_accuracy: 0.8543 - val_loss: 0.3386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Neural Network model saved as nn_model.h5\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "# Assuming your target column is named 'target'\n",
    "# Neural Network Model\n",
    "model = Sequential([\n",
    "    Input(shape=(x.shape[1],)),   # automatically uses 19 input features\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x,y, epochs=20, batch_size=32,\n",
    "                    validation_split=0.2, verbose=1)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"nn_model.h5\")\n",
    "print(\"✅ Neural Network model saved as nn_model.h5\")\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b995028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf1409a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m889/889\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step\n",
      "✅ Neural Network predictions saved to submission_nn.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_pickle(\"idealize_1_test.pkl\")\n",
    "\n",
    "# Save the 'id' column to merge later\n",
    "ids = df_test['id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_final_test = df_test.drop(['id','Day'], axis=1)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(\"nn_model.h5\")\n",
    "\n",
    "# Ensure input shape matches the training features (19 features expected)\n",
    "assert X_final_test.shape[1] == 19, \"Input data must have 19 features!\"\n",
    "\n",
    "# Predict probabilities\n",
    "pred_probs = model.predict(X_final_test)\n",
    "\n",
    "# Convert probabilities to class labels (0 or 1)\n",
    "predictions = (pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'RainTomorrow': predictions\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "submission.to_csv(\"submission_nn.csv\", index=False)\n",
    "print(\"✅ Neural Network predictions saved to submission_nn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230a36d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m best_model = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      5\u001b[39m best_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m.items():\n\u001b[32m      8\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m      9\u001b[39m     preds = model.predict(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_name = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"{name}: Accuracy = {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = model\n",
    "        best_name = name\n",
    "\n",
    "print(f\"\\nBest model: {best_name} with accuracy {best_acc:.4f}\")\n",
    "\n",
    "# Save the best model to a pickle file\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"Best model saved as 'best_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure RainTomorrow is categorical (0/1)\n",
    "if preprocessed_df['RainTomorrow'].dtype == float:\n",
    "    preprocessed_df['RainTomorrow'] = preprocessed_df['RainTomorrow'].round().astype(int)\n",
    "elif preprocessed_df['RainTomorrow'].dtype == object:\n",
    "    preprocessed_df['RainTomorrow'] = preprocessed_df['RainTomorrow'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandalearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
