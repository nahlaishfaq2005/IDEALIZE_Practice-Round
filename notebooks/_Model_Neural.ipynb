{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fa4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b014a",
   "metadata": {},
   "source": [
    "## Read Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48aca072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16388\\492529711.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  preprocessed_df = pd.read_csv(\"..\\Data\\processed\\preprocessed_train.csv\")\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = pd.read_csv(\"..\\Data\\processed\\preprocessed_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dee6cf",
   "metadata": {},
   "source": [
    "##  Train: Target variable  Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1f97be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113754 entries, 0 to 113753\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Location       113754 non-null  float64\n",
      " 1   MinTemp        113754 non-null  float64\n",
      " 2   MaxTemp        113754 non-null  float64\n",
      " 3   Rainfall       113754 non-null  float64\n",
      " 4   WindGustDir    113754 non-null  float64\n",
      " 5   WindGustSpeed  113754 non-null  float64\n",
      " 6   WindDir9am     113754 non-null  float64\n",
      " 7   WindDir3pm     113754 non-null  float64\n",
      " 8   WindSpeed9am   113754 non-null  float64\n",
      " 9   WindSpeed3pm   113754 non-null  float64\n",
      " 10  Humidity9am    113754 non-null  float64\n",
      " 11  Humidity3pm    113754 non-null  float64\n",
      " 12  Pressure9am    113754 non-null  float64\n",
      " 13  Pressure3pm    113754 non-null  float64\n",
      " 14  Temp9am        113754 non-null  float64\n",
      " 15  Temp3pm        113754 non-null  float64\n",
      " 16  Year           113754 non-null  float64\n",
      " 17  Month          113754 non-null  float64\n",
      " 18  Day            113754 non-null  int64  \n",
      " 19  RainToday_Yes  113754 non-null  float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 17.4 MB\n",
      "None\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 113754 entries, 0 to 113753\n",
      "Series name: RainTomorrow\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "113754 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 888.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = preprocessed_df.drop(columns=[\"RainTomorrow\"])\n",
    "y = preprocessed_df[\"RainTomorrow\"]\n",
    "\n",
    "print(x.info(5))\n",
    "print(y.info(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0a8a6",
   "metadata": {},
   "source": [
    "## Train: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "305fb360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RainTomorrow\n",
      "0    88252\n",
      "1    25502\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8439c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([     0,      1,      2,      3,      5,      6,      7,      8,     10,\\n           11,\\n       ...\\n       113741, 113742, 113743, 113744, 113745, 113747, 113748, 113749, 113750,\\n       113751],\\n      dtype='int32', length=91003)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîÅ Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m x_train, x_val \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m, x[val_idx]\n\u001b[0;32m     21\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_idx], y[val_idx]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Compute class weights for this fold\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([     0,      1,      2,      3,      5,      6,      7,      8,     10,\\n           11,\\n       ...\\n       113741, 113742, 113743, 113744, 113745, 113747, 113748, 113749, 113750,\\n       113751],\\n      dtype='int32', length=91003)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = dict(zip(np.unique(y), class_weights))\n",
    "print(\"‚úÖ Class weights:\", class_weights)\n",
    "\n",
    "# Step 2: Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(x.shape[1],)),   # automatically uses 19 input features\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # for binary classification\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# üîÅ Step 4: Train the model with class weights\n",
    "history = model.fit(x, y, \n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=1)\n",
    "\n",
    "# Step 5: Save the trained model\n",
    "model.save(r\"..\\outputs\\models\\nn_model.h5\")\n",
    "print(\"‚úÖ Neural Network model saved as nn_model.h5\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e0bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28439 entries, 0 to 28438\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Location       28439 non-null  float64\n",
      " 1   MinTemp        28439 non-null  float64\n",
      " 2   MaxTemp        28439 non-null  float64\n",
      " 3   Rainfall       28439 non-null  float64\n",
      " 4   WindGustDir    28439 non-null  float64\n",
      " 5   WindGustSpeed  28439 non-null  float64\n",
      " 6   WindDir9am     28439 non-null  float64\n",
      " 7   WindDir3pm     28439 non-null  float64\n",
      " 8   WindSpeed9am   28439 non-null  float64\n",
      " 9   WindSpeed3pm   28439 non-null  float64\n",
      " 10  Humidity9am    28439 non-null  float64\n",
      " 11  Humidity3pm    28439 non-null  float64\n",
      " 12  Pressure9am    28439 non-null  float64\n",
      " 13  Pressure3pm    28439 non-null  float64\n",
      " 14  Temp9am        28439 non-null  float64\n",
      " 15  Temp3pm        28439 non-null  float64\n",
      " 16  Year           28439 non-null  float64\n",
      " 17  Month          28439 non-null  float64\n",
      " 18  Day            28439 non-null  int64  \n",
      " 19  RainToday_Yes  28439 non-null  float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv(r\"..\\Data\\processed\\preprocessed_test.csv\")\n",
    "\n",
    "# Save the 'id' column to merge later\n",
    "ids = df_test['id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_final_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "X_final_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bea81",
   "metadata": {},
   "source": [
    "## Test: Prepare Subission file using test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b45609fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28439 entries, 0 to 28438\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Location       28439 non-null  float64\n",
      " 1   MinTemp        28439 non-null  float64\n",
      " 2   MaxTemp        28439 non-null  float64\n",
      " 3   Rainfall       28439 non-null  float64\n",
      " 4   WindGustDir    28439 non-null  float64\n",
      " 5   WindGustSpeed  28439 non-null  float64\n",
      " 6   WindDir9am     28439 non-null  float64\n",
      " 7   WindDir3pm     28439 non-null  float64\n",
      " 8   WindSpeed9am   28439 non-null  float64\n",
      " 9   WindSpeed3pm   28439 non-null  float64\n",
      " 10  Humidity9am    28439 non-null  float64\n",
      " 11  Humidity3pm    28439 non-null  float64\n",
      " 12  Pressure9am    28439 non-null  float64\n",
      " 13  Pressure3pm    28439 non-null  float64\n",
      " 14  Temp9am        28439 non-null  float64\n",
      " 15  Temp3pm        28439 non-null  float64\n",
      " 16  Year           28439 non-null  float64\n",
      " 17  Month          28439 non-null  float64\n",
      " 18  Day            28439 non-null  int64  \n",
      " 19  RainToday_Yes  28439 non-null  float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv(r\"..\\Data\\processed\\preprocessed_test.csv\")\n",
    "\n",
    "# Save the 'id' column to merge later\n",
    "ids = df_test['id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_final_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "# Load the trained neural network model\n",
    "X_final_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf1409a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m889/889\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "‚úÖ Neural Network predictions saved to submission_nn.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the test data\n",
    "df_test = pd.read_csv(r\"..\\Data\\processed\\preprocessed_test.csv\")\n",
    "\n",
    "# Save the 'id' column to merge later\n",
    "ids = df_test['id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_final_test = df_test.drop(['id'], axis=1)\n",
    "\n",
    "# Load the trained neural network model\n",
    "model = load_model(r\"..\\outputs\\models\\nn_model.h5\")\n",
    "\n",
    "# Ensure input shape matches the training features (19 features expected)\n",
    "assert X_final_test.shape[1] == 20, \"Input data must have 19 features!\"\n",
    "\n",
    "# Predict probabilities\n",
    "pred_probs = model.predict(X_final_test)\n",
    "\n",
    "# Convert probabilities to class labels (0 or 1)\n",
    "predictions = (pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'RainTomorrow': predictions\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "\n",
    "submission.to_csv(r\"..\\outputs\\submissions\\nn_model.csv\", index=False)\n",
    "print(\"‚úÖ Neural Network predictions saved to submission_nn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc492bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
